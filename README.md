# Цели проекта

1. Протестировать алгоритм распределения задач по соответствующим обработчикам
2. Попробовать выявить проблему дублирования задач по uid в кэше
3. Протестировать алгоритм сборки и отправки данных для мониторинга

### Реализация

API написал через MinimalAPI. Основной флоу такой, на сервер отправляется задача, сохраняется в кэш и распределяется на соответствующий обработчик. Данные мониторинга собираются и отправляются через веб-сокеты на клиент.
За сохранение в кэш отвечает `TaskCache`, за создание обработчиков (класс обработчика `TaskProcessor`) и распределение между ними задач отвечает `TaskBroker`. У каждого `TaskProcessor` есть своя очередь задач, в очереди хранятся uid задач.
Когда до задачи доходит очередь, то по uid она берется из кэша и обрабатывается, после чего выталкивается из очереди. За мониторинг отвечает `TaskMonitoring`, он обращается к `TaskCache` и `TaskBroker` за данными.
После сбора данных отправляет их на клиент через `TaskProcessorsMonitoringHub`. Работа с веб-сокетами реализована через SignalR. Клиент получает данные и обрабатывает их для отображения на графике. 
Работа с веб-сокетами на клиенте реализована через пакет `react-signalr`, а графики через пакет `@mui/x-charts` 

![AppScheme](https://github.com/Koichi-hub/TaskBrokerSandbox/blob/master/resources/app-scheme.png)

### Результат

Получилось веб-приложение, в котором можно добавить задачи, которые будут распределятся на соответствующие обработчики. Каждую секунду на графике отображаются данные по кол-ву задач в очереди у каждого обработчика.
А также отображается общее кол-во задач.

![UIChart](https://github.com/Koichi-hub/TaskBrokerSandbox/blob/master/resources/ui_chart.png)

### Итоги

1. Алгоритм справился со своей задачей
2. Проблему выявить не удалось. Случай дублирования можно обработать, либо отловить (если задачи сохраняются в БД)
3. Алгоритм справился со своей задачей 
